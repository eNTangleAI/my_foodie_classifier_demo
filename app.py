import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
import json
from huggingface_hub import hf_hub_download
from transformers import ViTForImageClassification
import os

# ---------------------------
# ì œëª© & ì•ˆë‚´
# ---------------------------
st.title("ğŸ± ìŒì‹ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° (ViT-B16 Demo)")

st.markdown("""
âš ï¸ **ë°ëª¨ ë²„ì „ ì•ˆë‚´**  
- ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ì—¬ ìŒì‹ ì´ë¦„ê³¼ ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.  

ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” Hugging Face Hubì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.
""")

# ---------------------------
# JSON ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------
with open("food_info.json", "r", encoding="utf-8") as f:
    food_info = json.load(f)

classes = list(food_info.keys())

# ---------------------------
# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Hugging Face Hubì—ì„œ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ)
# ---------------------------
@st.cache_resource
def load_model():
    repo_id = "eNtangedAI/my_foodie_classifier_demo"   # ì •í™•í•œ Hugging Face repo ì´ë¦„
    filename = "vit_best.pth"                          # Hubì— ì˜¬ë¼ê°„ weight íŒŒì¼ëª…

    # Streamlit Secretì—ì„œ HF_TOKEN ê°€ì ¸ì˜¤ê¸°
    token = os.getenv("HF_TOKEN")

    # Hubì—ì„œ ë‹¤ìš´ë¡œë“œ
    try:
        weight_path = hf_hub_download(repo_id=repo_id, filename=filename, token=token)
    except Exception as e:
        st.error(f"âŒ Hugging Face Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()
        
    # ViT ëª¨ë¸ êµ¬ì¡° ì •ì˜
    model = ViTForImageClassification.from_pretrained(
        "google/vit-base-patch16-224",
        num_labels=len(classes),
        ignore_mismatched_sizes=True
    )

    # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    model.load_state_dict(torch.load(weight_path, map_location="cpu"))
    model.eval()
    return model

model = load_model()

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

# ---------------------------
# íŒŒì¼ ì—…ë¡œë“œ
# ---------------------------
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png", "jpeg"])

# ---------------------------
# ì¶”ë¡  ì‹¤í–‰
# ---------------------------
if uploaded_file is not None:
    input_img = Image.open(uploaded_file).convert("RGB")
    st.image(input_img, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

    x = transform(input_img).unsqueeze(0)

    with torch.no_grad():
        outputs = model(x).logits
        pred = outputs.argmax(1).item()

    result = classes[pred]
    st.success(f"ì˜ˆì¸¡ ê²°ê³¼: **{result}**")

    info = food_info.get(result, None)
    if info:
        with st.expander("ğŸ½ï¸ ìŒì‹ ì¹´ë“œ í¼ì³ë³´ê¸°"):
            st.markdown(f"""
            **ì¹¼ë¡œë¦¬:** {info['ì¹¼ë¡œë¦¬']}  
            **ì£¼ìš” ì˜ì–‘ì†Œ:** {info['ì£¼ìš” ì˜ì–‘ì†Œ']}  
            **ì„¤ëª…:** {info['ì„¤ëª…']}  

            ğŸ¥‚ **ì¶”ì²œ í˜ì–´ë§:** {", ".join(info['ì¶”ì²œ í˜ì–´ë§'])}  
            ğŸµ **ì¶”ì²œ ìŒì•…:** {info['ì¶”ì²œ ìŒì•…']}  
            ğŸ¬ **ì¶”ì²œ ì˜í™”:** {info['ì¶”ì²œ ì˜í™”']}  
            """)
